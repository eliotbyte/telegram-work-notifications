import re
import logging
from bs4 import BeautifulSoup

def parse_jira_email(subject: str, raw_html: str) -> list[str] | None:
    """
    –ü–∞—Ä—Å–µ—Ä –ø–∏—Å–µ–º –æ—Ç Jira. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≥–æ—Ç–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è Telegram,
    –µ—Å–ª–∏ —ç—Ç–æ –ø–∏—Å—å–º–æ –ø—Ä–æ Jira –∏ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.

    - None, –µ—Å–ª–∏ –ø–∏—Å—å–º–æ –ù–ï –ø–æ—Ö–æ–∂–µ –Ω–∞ Jira (—Ç–æ–≥–¥–∞ –≤—ã–∑—ã–≤–∞—é—â–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ –ø–æ—à–ª—ë—Ç "–¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ" —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ).
    - –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ [], –µ—Å–ª–∏ –ø–∏—Å—å–º–æ - –¥–∂–∏—Ä–æ–≤—Å–∫–æ–µ, –Ω–æ –º—ã —Ä–µ—à–∏–ª–∏, —á—Ç–æ —É–≤–µ–¥–æ–º–ª—è—Ç—å –Ω–µ –æ —á–µ–º (–∏ –Ω—É–∂–Ω–æ
      —è–≤–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –ª–æ–≥–∏–∫—É).
    - –û–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥–æ—Ç–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –µ—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–±—ã—Ç–∏—è (–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ, —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∏ —Ç.–ø.).
    """

    lower_html = raw_html.lower()
    # –£–∑–Ω–∞—ë–º, –ø–æ—Ö–æ–∂–µ –ª–∏ –ø–∏—Å—å–º–æ –Ω–∞ Jira
    if "jira.task-cloud.ru" not in lower_html and "atlassian jira" not in lower_html:
        return None  # –ù–µ Jira ‚Äî –≤–µ—Ä–Ω—ë–º None, —á—Ç–æ–±—ã —Å—Ä–∞–±–æ—Ç–∞–ª–∞ –¥–µ—Ñ–æ–ª—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞

    soup = BeautifulSoup(raw_html, "html.parser")
    body_text = soup.get_text(separator=" ", strip=True).lower()

    # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ—É ‚Äî —Å—Å—ã–ª–∫—É –Ω–∞ –∑–∞–¥–∞—á—É:
    link_el = soup.find("a", href=re.compile(r"https://jira\.task-cloud\.ru/browse/[A-Z0-9]+-\d+"))
    if link_el:
        issue_url = link_el["href"]
        issue_key = link_el.get_text(strip=True)
    else:
        issue_url = None
        issue_key = None

    # –ü–∞—Ä—Å–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∑–∞–¥–∞—á–∏ (summary) –∏–∑ <h1>:
    summary_el = soup.find("h1")
    summary = summary_el.get_text(strip=True) if summary_el else ""

    # –°–æ–±–∏—Ä–∞–µ–º —É–¥–æ–±–Ω—ã–π –∫—É—Å–æ–∫ –¥–ª—è —Å—Å—ã–ª–∫–∏:
    if issue_url and issue_key:
        if summary:
            link_text = f'<a href="{issue_url}">[{issue_key}] {summary}</a>'
        else:
            link_text = f'<a href="{issue_url}">[{issue_key}]</a>'
    else:
        # fallback, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        link_text = subject

    # --- NEW LOGIC: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "Issue created" ---
    # –ï—Å–ª–∏ –ø–∏—Å—å–º–æ —Å–æ–¥–µ—Ä–∂–∏—Ç "issue created" –∏–ª–∏ "has been created", —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–µ.
    # –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ "üìå <–†–ï–ü–û–†–¢–ï–†> —Å–æ–∑–¥–∞–ª–∞(–∞) –∑–∞–¥–∞—á—É ..." –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –±–ª–æ–∫–∏.
    created_match = re.search(r"(issue created|has been created)", body_text)
    if created_match:
        # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –∏–º—è —Ä–µ–ø–æ—Ä—Ç–µ—Ä–∞. –î–≤–∞ —Å–ø–æ—Å–æ–±–∞:
        # 1) –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ —Ç–∞–±–ª–∏—Ü–µ "Reporter:"
        # 2) –∏–ª–∏ –Ω–∞–π—Ç–∏ —Ñ—Ä–∞–∑—É "<strong>–ò–ú–Ø</strong> created this issue on ..."

        reporter = None

        # —Å–ø–æ—Å–æ–± 1: –∏—â–µ–º —Å—Ç—Ä–æ–∫—É "Reporter:"
        field_rows = soup.find_all("tr", class_=re.compile(r"field-update|row"))
        for row in field_rows:
            label = row.find("td", class_=re.compile(r"updates-diff-label"))
            if label and "reporter:" in label.get_text(separator=" ", strip=True).lower():
                content_td = row.find("td", class_=re.compile(r"updates-diff-content"))
                if content_td:
                    a = content_td.find("a")
                    if a:
                        reporter = a.get_text(strip=True)
                    else:
                        reporter = content_td.get_text(strip=True)
                break

        # —Å–ø–æ—Å–æ–± 2 (fallback), –µ—Å–ª–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ –Ω–µ –Ω–∞—à–ª–∏:
        if not reporter:
            strong_tags = soup.find_all("strong")
            for s in strong_tags:
                # –∏—â–µ–º –Ω–∞–ø—Ä–∏–º–µ—Ä: "–ú–∏—â–∏—à–∏–Ω–∞ –î–∞—Ä–∏–Ω–∞ created this issue on"
                parent_text = s.parent.get_text(separator=" ", strip=True)
                if "created this issue on" in parent_text.lower():
                    reporter = s.get_text(strip=True)
                    break

        if not reporter:
            reporter = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–ø–æ—Ä—Ç—ë—Ä"

        single_msg = f"üìå {reporter} —Å–æ–∑–¥–∞–ª(–∞) –∑–∞–¥–∞—á—É {link_text}"
        return [single_msg]

    # --- NEW LOGIC: –ï—Å–ª–∏ –ø–∏—Å—å–º–æ –≥–æ–≤–æ—Ä–∏—Ç —Ç–æ–ª—å–∫–æ –æ worklog'–∞—Ö (–∏ –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ) ‚Äî –Ω–µ —É–≤–µ–¥–æ–º–ª—è—Ç—å ---
    # –ü—Ä–∏–º–µ—Ä: "There are 2 worklogs." –∏ –Ω–µ—Ç –¥—Ä—É–≥–∏—Ö —Å–ª–æ–≤ "update", "comment", "assigned", "created", "mention".
    # –°—á–∏—Ç–∞–µ–º, —á—Ç–æ —Ç–∞–∫–æ–µ –ø–∏—Å—å–º–æ –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ -> –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –Ω–∏—á–µ–≥–æ –Ω–µ —Å–ª–∞—Ç—å.
    if "there are" in body_text and "worklog" in body_text:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ –¥—Ä—É–≥–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (update, comment, mentioned, assign, created)
        has_other_keywords = any(
            kw in body_text
            for kw in [
                "update", "updates", "comment", "comments", "assigned to you",
                "mentioned in a comment", "issue created", "has been created"
            ]
        )
        if not has_other_keywords:
            # —Ç–æ–ª—å–∫–æ –≤–æ—Ä–∫–ª–æ–≥–∏ -> –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            return []

    parsed_messages = []

    # –ò—â–µ–º, –Ω–µ –Ω–∞–∑–Ω–∞—á–∏–ª–∏ –ª–∏ –Ω–∞—Å –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º:
    assigned_to_you = "assigned to you" in body_text

    # –ò—â–µ–º, –Ω–µ —É–ø–æ–º—è–Ω—É–ª–∏ –ª–∏ –Ω–∞—Å –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö:
    you_were_mentioned = (
        "mentioned in a comment" in body_text
        or "you've been mentioned in a comment" in body_text
    )

    # –ò—â–µ–º –∫–æ–ª-–≤–æ –∞–ø–¥–µ–π—Ç–æ–≤ (update/updates):
    updates_match = re.search(r"there (?:is|are) (\d+) update", body_text)
    updates_count = int(updates_match.group(1)) if updates_match else 0

    # –ò—â–µ–º –∞–≤—Ç–æ—Ä–æ–≤ "Changes by <strong>NAME>"
    strong_tags = soup.find_all("strong")
    changes_authors = []
    for s in strong_tags:
        parent_text = s.parent.get_text(separator=" ", strip=True).lower()
        if "changes by" in parent_text:
            changes_authors.append(s.get_text(strip=True))

    # CASE A: –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ ‚Äî –Ω–∞—Å –Ω–∞–∑–Ω–∞—á–∏–ª–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º
    if assigned_to_you and updates_count == 1 and len(changes_authors) == 1:
        author = changes_authors[0]
        parsed_messages.append(
            f"‚úÖ {author} –Ω–∞–∑–Ω–∞—á–∏–ª(–∞) –≤–∞—Å –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º –∑–∞–¥–∞—á–∏ {link_text}"
        )
    else:
        # –ï—Å–ª–∏ –≤—Å—ë –∂–µ –Ω–∞—Å –Ω–∞–∑–Ω–∞—á–∏–ª–∏, –Ω–æ –∞–ø–¥–µ–π—Ç–æ–≤ > 1 –∏–ª–∏ –∞–≤—Ç–æ—Ä–∞ –Ω–µ—Ç
        if assigned_to_you:
            parsed_messages.append(
                f"‚úÖ –í–∞—Å –Ω–∞–∑–Ω–∞—á–∏–ª–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º –∑–∞–¥–∞—á–∏ {link_text}"
            )

        # –ï—Å–ª–∏ –µ—Å—Ç—å updates_count > 0 –∏ –µ—Å—Ç—å –∞–≤—Ç–æ—Ä(—ã)
        if updates_count > 0 and changes_authors:
            for author in changes_authors:
                parsed_messages.append(
                    f"‚úèÔ∏è {author} –∏–∑–º–µ–Ω–∏–ª(–∞) –∑–∞–¥–∞—á—É {link_text}"
                )
        # –ï—Å–ª–∏ –∞–ø–¥–µ–π—Ç—ã –µ—Å—Ç—å, –Ω–æ –∞–≤—Ç–æ—Ä–∞ –Ω–µ—Ç
        elif updates_count > 0:
            parsed_messages.append(
                f"‚úèÔ∏è –í –∑–∞–¥–∞—á–µ {link_text} –µ—Å—Ç—å {updates_count} –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ(–∏–π)."
            )

    # CASE B: –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö
    if you_were_mentioned and issue_key and issue_url:
        mention_author = None
        for s in strong_tags:
            p_text = s.parent.get_text(separator=" ", strip=True).lower()
            if "mentioned in a comment" in p_text or "you've been mentioned in a comment" in p_text:
                continue
            if "on " in p_text and "changes by" not in p_text:
                mention_author = s.get_text(strip=True)
                break
        if not mention_author:
            mention_author = "–ö—Ç–æ-—Ç–æ"

        parsed_messages.append(
            f"üëÄ {mention_author} —É–ø–æ–º—è–Ω—É–ª(–∞) –≤–∞—Å –≤ –∑–∞–¥–∞—á–µ {link_text}"
        )

    # --- NEW LOGIC: –æ–¥–∏–Ω –æ–±—ã—á–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –Ω–∞—Å) ---
    # –¢—Ä–∏–≥–≥–µ—Ä: "There is 1 comment" + –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ñ—Ä–∞–∑—ã –æ —Ç–æ–º, —á—Ç–æ –Ω–∞—Å —É–ø–æ–º—è–Ω—É–ª–∏.
    if ("there is 1 comment" in body_text) and not you_were_mentioned:
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞–≤—Ç–æ—Ä–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è –≤ –±–ª–æ–∫–µ "1 comment".
        comment_author = None

        # –ò—â–µ–º tr c –∫–ª–∞—Å—Å–æ–º, –≤ –∫–æ—Ç–æ—Ä–æ–º –º–æ–∂–µ—Ç –±—ã—Ç—å –∞–≤—Ç–æ—Ä, –Ω–∞–ø—Ä–∏–º–µ—Ä "group-header"
        group_header = soup.find("tr", class_=re.compile(r"group-header"))
        if group_header:
            strong_tag = group_header.find("strong")
            if strong_tag:
                comment_author = strong_tag.get_text(strip=True)

        if not comment_author:
            comment_author = "–ö—Ç–æ-—Ç–æ"

        parsed_messages.append(
            f"üí¨ {comment_author} –æ—Å—Ç–∞–≤–∏–ª(–∞) –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –∑–∞–¥–∞—á–µ {link_text}"
        )

    # –ï—Å–ª–∏ –º—ã —á—Ç–æ-—Ç–æ –Ω–∞—Å–æ–±–∏—Ä–∞–ª–∏, –≤–µ—Ä–Ω—ë–º —Å–ø–∏—Å–æ–∫. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ–π
    return parsed_messages
